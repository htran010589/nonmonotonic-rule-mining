\chapter{Related Work}

The area of rule mining on knowledge graphs has attracted interests from many researchers recently. This problem can be classified into two main directions: statistics-based and logic-based approaches.

\section{Statistics-based Approach}

This direction focuses on building models with latent features which are not directly observable from the original data~\cite{ref1}. The core idea of this approach is to infer correlation between objects based on extracted hidden features. Besides, feature extraction is automatically executed in these methods.

RESCAL is one of principal algorithms in this direction where relations of any two hidden features are taken into consideration~\cite{ref2, ref3}. This method is extended to classical tensor decomposition algorithm~\cite{ref4} and neural tensor network~\cite{ref5}.

While many tensor factorization methods use subject, object, predicate as three dimensions to model knowledge graph as a cubic, some matrix decomposition algorithms try to transform this cubic into two dimensional data. For instance, subject and object dimensions are merged into one representing for pair of entities in~\cite{ref6, ref7}.

Some distance-based models use the intuition that entities have high chance to be related to each other if their hidden representation features are close. The closeness can be checked based on some distance measures. This approach can be expanded to structure embedding model~\cite{ref8}.

\section{Logic-based Approach}

The logic-based direction aims to find observable patterns in order to infer new links on the knowlege graph~\cite{ref1}. Since the patterns can be directly seen and not hidden in the data, these algorithms in this approach are more interpretable than those of the previous one. For instance, one pattern from the graph can be represented in a form:\\

\centerline{\textit{livesIn(Z, Y) $\leftarrow$ isMarriedTo(X, Z), livesIn(X, Y).}}

This form is equivalent to a triangle of three predicate edges in the knowledge graph. Since this pattern is frequent and observable, it can be mined in order to predict new links. More specifically, if we know some facts such as: \textit{isMarriedTo(Peter, Marry), livesIn(Marry, London)}; then the fact \textit{livesIn(Peter, London)} has high chance to be true.

In the rest of this section, the following main systems in this approach are discussed in details.

\subsection{Inductive Logic Programming Systems}

Inductive Logic Programming~\cite{ref9} (ILP) is a combination field of Machine Learning and Logic Programming and it is used for generating hypothesis based on background knowledge, specific examples. These examples can be classified into positive and negative groups. The hypothesis is true for every positive example and not true for any negative one.

Rule mining is a core problem in ILP, however, applying ILP algorithms to semantic web data is problematic for the following reasons. Firstly, ILP tools are not scalable and efficient for large knowlege graph such as YAGO, Freebase, Wikidata~\cite{ref10}. 

Secondly, ILP methods use closed world assumption (CWA), that is, it is assumed that knowlege base is complete and missing facts are false. These methods require both positive and negative examples like traditional machine learning algorithms. This assumption and requirement are not suitable for our problem since there are only in-completed positive facts in real world data~\cite{ref10}.

Thirdly, most ILP algorithms generate positive Horn rules without exceptions~\cite{ref11}. Since mining exceptions is important purpose of our work, naively using ILP tools will not produce what we want. This is also the reason why Abductive Logic Programming~\cite{ref11} should be taken into account.

(should I describe ALP here?)

To be filled (WARMR, QuickFoil, ...)

\subsection{AMIE+ System}

The scalability and CWA assumption issues of ILP are tackled in AMIE~\cite{ref10} system. This tool receives a large knowledge graph as an input and generates top positive Horn rules with high quality.

AMIE+ is a new version of AMIE in which run time performance is enhanced by pruning and query manipulations. Experimental work in~\cite{ref10} shows that this platform can process millions of triples in RDF graph and its mined rules surpass those of other methods in terms of efficiency.

However, like other ILP platforms, AMIE+ does not take care nonmonotonic rules or exceptions since its output is a list of Horn rules. Our work can solve this problem since it aims to generate rules with exceptions from a list of AMIE+ mined positive rules and a big knowledge graph.

\subsection{Nonmonotonic Rule Mining System}

This research works on flattened knowledge graph, i.e, the graph that all RDF triples are converted to unary facts by concatenating predicates and objects.

After positive rules are mined using Association Rule Mining tools, the exceptions for each rule are found based on normal and abnormal sets. In the next step, these negative atoms are ranked based on several score measures and innovative concept of partial materialization.

This thesis treats the knowledge graph in the nature format instead of flattened one.
